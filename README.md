<div align="center">

# **Proyecto IA ML â€“ IntroducciÃ³n a Deep Learning**  
### Redes Neuronales aplicadas a datos reales  
**Autor:** *RamÃ³n Terraza*  
**Universidad Galileo**  
**2025**

---

## Arquitecturas Implementadas
- **MLP** (Big Five Personality Prediction)  
- **CNN** (ClasificaciÃ³n de Tortugas Tierra vs Agua)  
- **RNN â€“ BiLSTM** (ClasificaciÃ³n de Frases en Dovahzul, idioma ficticio del juego The Elder Scrolls V: Skyrim)

---

### ğŸ“Š Datasets Table

| Proyecto | Dataset | Fuente | Enlace |
|----------|---------|---------|--------|
| **MLP** | Big Five Personality Test (â‰ˆ1M respuestas) | Kaggle | [Dataset en Kaggle](https://www.kaggle.com/datasets/tunguz/big-five-personality-test/data) |
| **CNN** | Tortoise Images Dataset (land vs water) | Varias fuentes (Kaggle, Images.CV, imÃ¡genes filtradas manualmente) |  Kaggle: [Dolphin/Tortoise Dataset](https://www.kaggle.com/datasets/deepakat002/dolphintortoise?resource=download&select=ff9d9ce2602aeafe.jpg) <br>  images.cv Dataset: [Tortoise Classification Dataset](https://images.cv/dataset/tortoise-image-classification-dataset) <br>  images.cv Search: [Turtle Labeled Images](https://images.cv/search-labeled-image-dataset?query=Turtle) |
| **RNN** | Dovahzulâ€“English Parallel Corpus | Dataset personalizado + ampliado | [Thuum.org â€“ secciÃ³n *Downloads*](https://www.thuum.org/) |

---



</div>


---

# Comparativa General de Modelos

| CaracterÃ­stica | **MLP â€“ Big Five** | **CNN â€“ Tortugas** | **RNN â€“ Dovahzul** |
|----------------|---------------------|---------------------|---------------------|
| Tipo de problema | ClasificaciÃ³n (5 clases) | ClasificaciÃ³n (2 clases) | ClasificaciÃ³n (6 clases) |
| Dataset | 1M+ filas (tras limpieza â‰ˆ 850k) | 1,200 imÃ¡genes (seleccionadas) | 8,000+ frases (ampliadas) |
| Input | 50 respuestas Likert + atributos | Imagen 224Ã—224 RGB | Secuencia de caracteres |
| Arquitectura | 4 capas densas + Dropout | 3 bloques Conv-BN-ReLU | BiLSTM + Embeddings |
| Optimizador | Adam | Adam + LR Scheduler | Adam |
| RegularizaciÃ³n | Dropout | Data Augmentation | Oversampling + Dropout |
| Accuracy final test | **â‰ˆ 80% - 90%** | **â‰ˆ 86%** | **â‰ˆ 83%** |
| MÃ©trica F1-score | F1-score macro â‰ˆ 0.80 | F1-score â‰ˆ 0.86 | F1-score macro â‰ˆ 0.82 |
| Limitaciones | Dataset ruidoso | Dataset pequeÃ±o | Clases desbalanceadas |
| Posibles mejoras | NormalizaciÃ³n avanzada | Transfer learning (ResNet) | Transformers |

---

# Arquitectura Global del Proyecto

```ascii
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚        DATASETS           â”‚
                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                           â”‚ Big Five (MLP)            â”‚
                           â”‚ Tortugas (CNN)            â”‚
                           â”‚ Dovahzul (RNN)            â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   PREPROCESAMIENTO POR MODELO      â”‚
                       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚ MLP: Limpieza NaN, estandarizaciÃ³n â”‚
                       â”‚ CNN: Split imÃ¡genes + augmentation â”‚
                       â”‚ RNN: TokenizaciÃ³n + balanceo       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚            â”‚
                                     â–¼            â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    MLP MODEL       â”‚   â”‚     CNN MODEL        â”‚   â”‚      RNN MODEL      â”‚
         â”‚ Big Five Predictionâ”‚   â”‚ Tortoise Classifier  â”‚   â”‚ Dovahzul Classifier â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ Dense layers +     â”‚   â”‚ Conv2D + BN + ReLU   â”‚   â”‚ Embedding + BiLSTM  â”‚
         â”‚ dropout + Adam     â”‚   â”‚ Fully Connected head â”‚   â”‚ Fully Connected head â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                       â”‚                          â”‚
                    â–¼                       â–¼                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   TRAIN LOOP   â”‚      â”‚   TRAIN LOOP    â”‚       â”‚    TRAIN LOOP       â”‚
            â”‚  Loss + metricsâ”‚      â”‚  Augmentation   â”‚       â”‚ CrossEntropy + F1   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                        â”‚                           â”‚
                     â–¼                        â–¼                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   VALIDACIÃ“N   â”‚       â”‚  VALIDACIÃ“N    â”‚      â”‚     VALIDACIÃ“N     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                        â”‚                          â”‚
                     â–¼                        â–¼                          â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     TEST + F1      â”‚   â”‚  TEST + CONFUSION    â”‚   â”‚ TEST + MATRIZ CONF â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Mas sobre datasets utilizados

### Big Five Personality Test â€” 1M samples (Kaggle)

Dataset masivo con mÃ¡s de 1 millÃ³n de respuestas.
Incluye 50 Ã­tems (OCEAN) evaluados en escala Likert.

Variables:

- 50 preguntas del test OCEAN
- Etiqueta generada: rasgo dominante (O, C, E, A, N)
- siendo: ClasificaciÃ³n multiclase (5 clases)

### Tortoise Classification (Water vs Land)

Dataset descargado desde images.cv, kaggle y seleccion de imagenes con carpetas separadas:

/land â†’ tortugas terrestres

/water â†’ tortugas marinas

Transformaciones aplicadas:

- RandomResizedCrop
- HorizontalFlip
- Rotation
- ColorJitter
- siendo: ClasificaciÃ³n binaria

### Dovahzulâ€“English Parallel Corpus (Dragon Language)

Dataset con  frases traducidas del lenguaje ficticio Dovahzul.
Se generaron etiquetas nuevas:

- greeting
- power
- attack
- object
- action
- other

siendo: ClasificaciÃ³n multiclase con texto
Se aplicaron embeddings + LSTM bidireccional.

## Modelos Implementados

### MLP â€” Big Five Personality Prediction

Notebook: 01_MLP.ipynb

Arquitectura: 

- 3 capas densas ocultas
- ActivaciÃ³n ReLU
- Dropout en todas las capas
- NormalizaciÃ³n de datos
- Optimizador Adam
- CrossEntropy para clasificaciÃ³n de 5 clases

Resultados principales:

- Accuracy (test): ~80% - 90%
- Mejoras obtenidas:
- Limpieza agresiva de NaNs en 50 Ã­tems
- EliminaciÃ³n de respuestas invÃ¡lidas (cÃ³digo = 0)
- Balanceo de clases

Modelo MLP (3â€“5 capas)

### CNN â€” ClasificaciÃ³n de tortugas tierra vs agua

Notebook: 02_CNN.ipynb

Arquitectura:

- 3 bloques Conv2D + BatchNorm + ReLU + MaxPool
- Capa fully connected con Dropout
- Data augmentation agresiva
- Scheduler ReduceLROnPlateau

Resultados principales:

- Accuracy en Test: ~86%
- Precision y Recall balanceados
- Matriz de confusiÃ³n estable y sin sesgo por clase

### RNN (BiLSTM) â€” ClasificaciÃ³n de frases en Dovahzul

Notebook: 03_RNN.ipynb

Arquitectura:

- Embedding layer
- LSTM bidireccional de 128 unidades
- Capa fully connected para clasificaciÃ³n
- Stratified sampling + oversampling por clase
- TokenizaciÃ³n carÃ¡cterâ€“nivel

Resultados principales

- Accuracy en Test: ~83%
- F1-score equilibrado entre clases subrepresentadas
- Matriz de confusiÃ³n con pocas confusiones semÃ¡nticas



## Conclusiones Finales

### Aprendizaje:
- ConstrucciÃ³n de pipelines de Deep Learning
- Tratamiento de datasets reales, ruidosos y desbalanceados
- Uso correcto de train/val/test
- Entrenamiento con GPU y optimizaciÃ³n mediante LR scheduler

### ImplementaciÃ³n de 3 arquitecturas distintas:
- MLP
- CNN
- RNN (LSTM)

### DesafÃ­os
- Limpieza del dataset Big Five
- Balanceo de clases en Dovahzul
- Overfitting en el modelo CNN

### Posibles mejoras

- Implementar Transformers para NLP
- Usar transfer learning en visiÃ³n (ResNet, EfficientNet)
- Implementar un VAE para generaciÃ³n de frases o perfiles de personalidad
- Aplicar tÃ©cnicas de hiperparÃ¡metros (Optuna, Ray Tune)